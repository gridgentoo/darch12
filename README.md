![alt text](https://covers.oreillystatic.com/images/0636920065869/lrg.jpg)
![alt text](https://covers.oreillystatic.com/images/0636920063698/lrg.jpg)
![alt text](https://images.manning.com/720/960/resize/book/2/a05976a-7251-47f4-a168-a84715e8b701/Stevens-DLPy-MEAP-HI.png)
![alt text](https://covers.oreillystatic.com/images/0636920063445/rc_lrg.jpg)

# [AnchorModeling] for Input–output model [Межотраслевые Балансы]
![alt text](http://www.anchormodeling.com/wp-content/uploads/2010/08/AMatDSV.jpg)

[ClickHouse vs Vertica vs GreenPlum] Сравнение производительности аналитических СУБД  
https://clickhouse.yandex/benchmark.html


# darch12
**Скрипты к статьям (RU)**

PartI - [Глубокие нейросети (Часть I). Подготовка данных](https://www.mql5.com/ru/articles/3486)
        
PartII - [Глубокие нейросети (Часть II). Разработка и выбор предикторов](https://www.mql5.com/ru/articles/3507)

PartIII - [Глубокие нейросети (Часть III). Выбор примеров и уменьшение размерности](https://www.mql5.com/ru/articles/3526)

PartIV - [Глубокие нейросети (Часть IV). Создание, обучение и тестирование модели нейросети](https://www.mql5.com/ru/articles/3473)
         
PartV - [Глубокие нейросети (Часть V). Байесовская оптимизация гиперпараметров DNN](https://www.mql5.com/ru/articles/4225)
        
PartVI - [Глубокие нейросети (Часть VI). Ансамбль нейросетевых классификаторов: bagging](https://www.mql5.com/ru/articles/4227)//
    
PartVII - [Глубокие нейросети (Часть VII). Ансамбль нейросетей: stacking](https://www.mql5.com/ru/articles/4228)

PartVIII - [Глубокие нейросети (Часть VIII). Повышение качества классификации bagging ансамблей](https://www.mql5.com/ru/articles/4722)

*В статье рассмотрим три возможных метода повышения качества классификации bagging ансамблей полученных в предыдущей статье. Первый - обработка шумовых примеров несколькими способами. Второй - выбор оптимальных порогов перевода непрерывных предсказаний в метки классов. Третий - объединение нескольких ансамблей в суперансамбль а их предсказания каскадно голосованием простым большинством. Кроме этого мы рассмотрим насколько оптимизация гиперпараметров нейросетей ELM и параметров постпроцессинга (обрезка и усреднение) влияют на качество классификации ансамбля. В заключение проведем анализ результатов и определим какие методы наиболее эффективны для повышения качества классификации ансамблей.*

***

**Scripts to articles (EN)** 

PartI - [Deep Neural Networks (Part I). Preparing Data ](https://www.mql5.com/en/articles/3486)

PartII -[Deep Neural Networks (Part II). Working out and selecting predictors](https://www.mql5.com/en/articles/3507)

PartIII -[Deep Neural Networks (Part III). Sample selection and dimensionality reduction](https://www.mql5.com/en/articles/3526)

PartIV - [Deep Neural Networks (Part IV). Creating, training and testing a model of neural network ](https://www.mql5.com/en/articles/3473)

PartV - [Deep Neural Networks (Part V). Bayesian optimization of DNN hyperparameters](https://www.mql5.com/en/articles/4225)

PartVI - [Deep Neural Networks (Part VI). Ensemble of neural network classifiers: bagging](https://www.mql5.com/en/articles/4227)

